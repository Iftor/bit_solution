# -*- coding: utf-8 -*-
"""analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1szXtoxGq4Ok_glqrqe0cw4bZPAIPhVrN

# Data Import
***
Here we import telecom data set, which has information about users and whether they left the company (Churn)

***
Import and take a look at the data
"""

import pandas as pd
import numpy as np

train = pd.read_csv('Data-Mining-Project/data/train.csv')
train.head()

"""***
Check for missing values and delete them
"""

init_len = len(train)
print(train.isna().sum())
train = train.dropna()
test = test.dropna()
print(f"\nData left: {len(train)}/{init_len}")

mask = train['TotalSpent'] == ' '
train.loc[mask, 'TotalSpent'] = train.loc[mask, 'MonthlySpending'].astype('string')

print(train.TotalSpent.dtype) # not good
print(train.TotalSpent.sort_values(ascending=True).values)
mask = train['TotalSpent'] == ' '
# train.TotalSpent = train.TotalSpent.replace(' ', 1)

train.TotalSpent = train.TotalSpent.astype(float)

"""# Exploratory Data Analysis
***
Here we perform:
1. See variable distributions.
2. Encode variables.
3. Correlations between variables.
<br> <br>

From this section we conclude:
1. Class disbalance can be seen
2. People with month-to-month contract are tend to leave the company.
3. People with highest client period are most loyal and hence less likely to leave the company.
4. Numerical features such as ClientPeriod, MonthlySpending, TotalSpent are significant to analysis.
5. By building Decision Treee, We can deduce several main rules when determining the Churn of users.

***
<div class="alert alert-block alert-info">
Class disbalance can be seen in data. That means balancing methods could improve model performance
</div>
"""

cat_cols = []
bin_cols = []
num_cols = []
for col in train.columns.tolist():
    if len(train[col].value_counts()) > 2 and len(train[col].value_counts())<10:
        cat_cols.append(col)
    elif len(train[col].value_counts()) == 2:
        bin_cols.append(col)
    else:
        num_cols.append(col)

import matplotlib.pyplot as plt

# Print target class value counts
print(f"Target class value counts: \n{train['Churn'].value_counts()}")

# Plot a pie chart for the target variable distribution
plt.figure(figsize=(3, 3))
plt.title("Target Variable Distribution", fontsize=8)
train['Churn'].value_counts().plot.pie(autopct='%1.1f%%', labels=['Not Churned', 'Churned'], colors=['lightblue', 'lightcoral'])
plt.axis('equal')  # Equal aspect ratio ensures that the pie chart is circular.
plt.show()

nrows, ncols = 4, 4
fig, axes = plt.subplots(nrows, ncols, figsize=(20, 20), sharey=True)
ax = axes.ravel()
fig.suptitle('Categorical and binary feature distributions for train', fontsize=15)
for i, cat in enumerate(cat_cols + bin_cols[:-1]):
    x = train[cat].value_counts()
    index = x.index
    if cat == 'PaymentMethod':
        index = [i for i in range(len(index))]
    ax[i].bar(x=index, height=x, color=['wheat', 'chocolate', 'peru', 'orange'], edgecolor='black')
    ax[i].set_title(cat)

"""***
Find numerical, categorical and binary variables in data
"""

from sklearn.preprocessing import LabelEncoder, OneHotEncoder


encoder = LabelEncoder()
train[bin_cols] = train[bin_cols].apply(LabelEncoder().fit_transform)
train = pd.concat((train[bin_cols + num_cols], pd.get_dummies(train[cat_cols])), axis=1)

import matplotlib.pyplot as plt
import seaborn as sns


fig, ax = plt.subplots(1, figsize=(10, 10))
q = pd.DataFrame(train.drop(columns=['Churn']).corrwith(train['Churn']).sort_values(ascending=False)).transpose()
sns.barplot(data=q, orient='h')
ax.set(title='Correlation betweet Features and Churn');

"""***
Perform Mann Whitney test to check if numerical values affect Churn distribution

H0 - Data is retrieved from same distribution, no difference between churn / non-churn users -> variables are useless in analysis
"""

from scipy.stats import mannwhitneyu

isgone = train[train['Churn'] == 1]
ishere = train[train['Churn'] == 0]

# H0 - Data is retrieved from same distribution, no difference between churn / non-churn users -> variables are useless in analysis
for i, cat in enumerate(num_cols):
    p = mannwhitneyu(isgone[cat], ishere[cat]).pvalue
    print(f'p-value for feature {cat} is {p}, should we reject H0? - {["NO", "YES"][bool(p < 0.01)]}') #без bool выходит предупреждение

from sklearn.tree import DecisionTreeClassifier, plot_tree

clf = DecisionTreeClassifier(min_impurity_decrease=0.002)
clf.fit(train.drop(columns=['Churn']), train['Churn'])
plt.figure(figsize=(20, 8))
plot_tree(clf, fontsize=14, feature_names=train.drop(columns=['Churn']).columns, filled=True)
plt.show()

sns.pairplot(train[num_cols+['Churn']], hue="Churn")

"""# Preprocessing

***
In this section we perform:
1. Over sampling.
2. Train-Test split.
3. Normalization. Standard Scaler

Label and OneHot encoding are done in previous section, to permorm EDA on these variables.
"""

from imblearn.over_sampling import SMOTE
import numpy as np

def undersample(df):
    class_0 = df[df['Churn'] == 0].sample(1106)
    class_1 = df[df['Churn'] == 1]
    return pd.concat([class_0, class_1], axis=0)

def oversample(df):
    class_0 = df[df['Churn'] == 0]
    class_1 = df[df['Churn'] == 1].sample(3111, replace=True)
    return pd.concat([class_0, class_1], axis=0)




train = oversample(train)
# train

X_train, X_val, y_train, y_val= train_test_split(train.drop(columns=['Churn']), train['Churn'], test_size=.25, random_state=777)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_val[num_cols] = scaler.transform(X_val[num_cols])

"""# Train Models
***
In this section we:
1. Train models such as: LogRegression, KNN, GradientBoosting, RandomForest
2. Use RandomForest to retrieve feature importances.

## Logistic Regression
"""

from sklearn.linear_model import LogisticRegressionCV

Cs = np.logspace(-3, 2, 30)
logcv = LogisticRegressionCV(Cs=Cs, random_state=123, scoring='roc_auc')
logcv.fit(X_train, y_train)
best_C = logcv.C_[0]

plt.figure(figsize=(10, 6))
sns.lineplot(y=logcv.scores_[1].mean(axis=0), x=logcv.Cs_)
plt.axvline(logcv.C_, ls='--', color='r', label='best C')
plt.legend()

y_train_predicted = logcv.predict_proba(X_train)[:, 1]
y_test_predicted = logcv.predict_proba(X_val)[:, 1]

roc_auc_score(y_val, logcv.predict_proba(X_val)[:, 1])

from sklearn.metrics import roc_auc_score, roc_curve

fig, ax = plt.subplots(figsize=(10, 8))
ax.plot(*roc_curve(y_val, y_test_predicted)[:2], label='test')
ax.plot(*roc_curve(y_train, y_train_predicted)[:2], label='train')
ax.legend()
ax.set(xlabel='False positive rate', ylabel='True positive rate', title=f'ROC_AUC Linear Regression with C = {round(best_C, 5)}')
ax.grid()
ax.set_yticks(np.linspace(0, 1, 11))
ax.set_xticks(np.linspace(0, 1, 11));

roc_auc_score(y_val, logcv.predict_proba(X_val)[:, 1])

"""## KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

neigh = KNeighborsClassifier()
parameters = {'n_neighbors': [i for i in range(40, 43)],
             'metric': ['manhattan'],
             }
grid_search = GridSearchCV(estimator=neigh, param_grid=parameters, cv=10, refit=True, scoring="roc_auc", n_jobs=-1,)
knn = grid_search.fit(X_train, y_train)

print(f"best score: {knn.best_score_}")
print(f"best params: {knn.best_params_}")

roc_auc_score(y_val, knn.predict_proba(X_val)[:, 1])

"""## Gradient boosting"""

from catboost import CatBoostClassifier

catboost = CatBoostClassifier(
    cat_features=X_train.nunique()[X_train.nunique() == 2].index.tolist(),
    logging_level="Silent",
    eval_metric="AUC:hints=skip_train~false",
    grow_policy="Lossguide",
    metric_period=1000,
    random_seed=42,
    loss_function='CrossEntropy',
#     task_type='GPU',
    early_stopping_rounds=10
)

PARAMS = {
    "n_estimators": [300, 500, 700, 1000],  # [5, 10, 20, 30, 40, 50, 70, 100, 150, 200, 250, 300, 500, 1000],
    "learning_rate": [0.05],  # [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.04, 0.05, 0.1, 0.2, 0.3, 0.5],
    "max_depth": [4],  # np.arange(4, 20, 1),
    "l2_leaf_reg": [10],  # np.arange(0.1, 1, 0.05),
    "subsample": [0.6],  # [3, 5, 7, 10],
#     "random_strength": [2, 5, 8],  # [1, 2, 5, 10, 20, 50, 100],
    "min_data_in_leaf": [100],  # np.arange(10, 1001, 10),
#     'task_type': ['GPU'],
#     'early_stopping_rounds': [10],
}
catboost.grid_search(PARAMS, X_train, y_train, cv=5, plot=True, refit=True)

print("Best score:", end=' ')
print(catboost.best_score_)
best_params = catboost.get_params()
for f in ("cat_features", "logging_level", "eval_metric"):
    best_params.pop(f)
print("Best params:", end=' ')
print(best_params)

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier

PARAMS = {
    "min_samples_split": [9],  # range(2, 200),
    "min_samples_leaf": [19],  # range(1, 200),
}
clf = RandomForestClassifier(n_estimators=200, random_state=42)

grid_search = GridSearchCV(clf, PARAMS, scoring="roc_auc", cv=5)
rf = grid_search.fit(X_train, y_train);

pd.DataFrame(rf.best_estimator_.feature_importances_, index=X_train.columns, columns=["importance"]) \
    .sort_values("importance") \
    .plot(kind="barh", legend=False, figsize=(12, 8));
plt.title("Feature importance");

print(f"Best score: {rf.best_score_}")
print(f"Best params: {rf.best_params_}")

"""## Best model submition
Kaggle test score 0.85
"""

test = pd.read_csv('Data-Mining-Project/data/test.csv')
test.TotalSpent = test.TotalSpent.replace(' ', 1)
test.TotalSpent = test.TotalSpent.astype(float)
test.head()

cat_cols = []
bin_cols = []
num_cols = []
for col in test.columns.tolist():
    if len(test[col].value_counts()) > 2 and len(test[col].value_counts())<10:
        cat_cols.append(col)
    elif len(test[col].value_counts()) == 2:
        bin_cols.append(col)
    else:
        num_cols.append(col)


encoder = LabelEncoder()
test[bin_cols] = test[bin_cols].apply(LabelEncoder().fit_transform)
test = pd.concat((test[bin_cols + num_cols], pd.get_dummies(test[cat_cols])), axis=1)


test[num_cols] = scaler.transform(test[num_cols])

submission = pd.read_csv("Data-Mining-Project/data/submission.csv")
submission["Churn"] = catboost.predict_proba(test)[:, 1]
submission.to_csv("Data-Mining-Project/data/catboost_sub.csv", index=False)





